{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Set Test Result: False\n",
      "Searching in the Hash Set Took: 0.00019288063049316406\n",
      "List Test Result: False\n",
      "Searching in the List Took: 0.1782698631286621\n"
     ]
    }
   ],
   "source": [
    "# Define a function to demonstrate the operation and time complexity of a hash set\n",
    "def hash_set_operations():\n",
    "  \n",
    "    # Importing the necessary libraries\n",
    "    import time\n",
    "    \n",
    "    # Create a hash set and a list\n",
    "    hash_set = set()\n",
    "    list_data = []\n",
    "    \n",
    "    # Setting the range for the data elements\n",
    "    data_range = 10**7\n",
    "    \n",
    "    # Adding elements to the hash set and the list\n",
    "    for i in range(data_range):\n",
    "        hash_set.add(i)\n",
    "        list_data.append(i)\n",
    "        \n",
    "    # Define a test element (which is out of the data range and thus is not present in both the list and set)\n",
    "    test_element = data_range + 1\n",
    "    \n",
    "    # Start the clock and check for the presence of the test elements in the set\n",
    "    start_time = time.time()\n",
    "    print(\"Hash Set Test Result:\", test_element in hash_set)\n",
    "    print(\"Searching in the Hash Set Took:\", time.time() - start_time)\n",
    "  \n",
    "    # Start the clock and check for the presence of the test elements in the list\n",
    "    start_time = time.time()\n",
    "    print(\"List Test Result:\", test_element in list_data)\n",
    "    print(\"Searching in the List Took:\", time.time() - start_time)\n",
    "\n",
    "# Call the function\n",
    "hash_set_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Set Test Result 1: False\n",
      "Hash Set Test Result 2: True\n",
      "Searching in the Hash Set Took: 0.0009441375732421875\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary module\n",
    "import time\n",
    "\n",
    "# Define a function to demonstrate the operation and time complexity of hash sets\n",
    "def hash_set_operations():\n",
    "  \n",
    "    # Create a new hash set \n",
    "    names_set = set()\n",
    "\n",
    "    # Setting the range for the data elements\n",
    "    data_range = 10**7\n",
    "\n",
    "    # Constructing a unique names list\n",
    "    unique_names = ['Name' + str(i) for i in range(data_range)]\n",
    "\n",
    "    # Adding elements to the set\n",
    "    for i in range(data_range):\n",
    "        names_set.add(unique_names[i])\n",
    "\n",
    "    # Define a test element (which is out of the data range and thus is not present in the set)\n",
    "    test_name = 'Name' + str(data_range + 1)\n",
    "\n",
    "    # Define a test element that should exist\n",
    "    test_name2 = 'Name' + str(data_range - 1)\n",
    "\n",
    "    # Start the clock and check for the presence of the test elements in the set\n",
    "    start_time = time.time()\n",
    "    print(\"Hash Set Test Result 1:\", test_name in names_set)\n",
    "    print(\"Hash Set Test Result 2:\", test_name2 in names_set)\n",
    "    print(\"Searching in the Hash Set Took:\", time.time() - start_time)\n",
    "\n",
    "# Call the function\n",
    "hash_set_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def compare_operations():\n",
    "    # Create a list and a set\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    data_set = set()\n",
    "\n",
    "\n",
    "\n",
    "    # Adding elements to list and set\n",
    "\n",
    "    for i in range(10**6):\n",
    "\n",
    "        data_list.append(i)\n",
    "\n",
    "        data_set.add(i)\n",
    "\n",
    "\n",
    "\n",
    "    # Set and List are ready; now let's define a non-existing item to search for\n",
    "\n",
    "    test_item = 10**6 + 1 \n",
    "\n",
    "    # Time the 100 consecutive operations of checking whether `test_item` is in `data_set`\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        if test_item in data_set:\n",
    "            pass  # Do nothing if found (expected not to find)\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken for 100 set lookups:\", end_time - start_time)\n",
    "\n",
    "    # Time the 100 consecutive operations of checking whether `test_item` is in `data_list`\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        if test_item in data_list:\n",
    "            pass  # Do nothing if found (expected not to find)\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken for 100 list lookups:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to demonstrate the operation and time complexity of a hash set\n",
    "\n",
    "def compare_operations():\n",
    "\n",
    "  \n",
    "\n",
    "    # Create a list and a set\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    data_set = set()\n",
    "\n",
    "\n",
    "\n",
    "    # Adding elements to list and set\n",
    "\n",
    "    for i in range(10**6):\n",
    "\n",
    "        data_list.append(i)\n",
    "\n",
    "        data_set.add(i)\n",
    "\n",
    "\n",
    "\n",
    "    # Set and List are ready; now let's define a non-existing item to search for\n",
    "\n",
    "    test_item = 10**6 + 1  # This item is not in our set or list\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: Time the 100 consecutive operations of checking whether `test_item` is in `data_set` and print the result and time taken\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: Time the 100 consecutive operations of checking whether `test_item` is in `data_list` and print the result and time taken\n",
    "\n",
    "\n",
    "\n",
    "# Execute the function\n",
    "\n",
    "compare_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the instersection of elements in two lists using sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 8, 7, 6, 5]\n",
      "[-1, -2, -3, -4, -5]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def intersecting_elements(set1, set2):\n",
    "    # implement this\n",
    "    set1 = set(set1)\n",
    "    set2 = set(set2)\n",
    "    intersection = set1 & set2\n",
    "    return sorted(list(intersection),reverse=True)\n",
    "    pass\n",
    "\n",
    "print(intersecting_elements({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {5, 6, 7, 8, 9, 10, 11, 12, 13, 14}))\n",
    "# Expected output: [10, 9, 8, 7, 6, 5]\n",
    "\n",
    "print(intersecting_elements({-1, -2, -3, -4, -5}, {-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5}))\n",
    "# Expected output: [-1, -2, -3, -4, -5]\n",
    "\n",
    "print(intersecting_elements({1, 3, 5, 7, 9}, {2, 4, 6, 8, 10}))\n",
    "# Expected output: []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using set to find repeating elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7]\n",
      "[2, 3, -1]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def repeating_elements(nums):\n",
    "    # implement this\n",
    "    seen , repeated = set(),set()\n",
    "    for num in nums:\n",
    "        if num in seen:\n",
    "            repeated.add(num)\n",
    "        else:\n",
    "            seen.add(num)\n",
    "    return list(repeated)\n",
    "    pass\n",
    "\n",
    "print(repeating_elements([9, 8, 7, 8, 7, 6, 5]))  # expected output : [8, 7]\n",
    "print(repeating_elements([-1, 2, 3, -1, 2, 3]))   # expected output : [-1, 2, 3]\n",
    "print(repeating_elements([1, 2, 3, 4, 5]))        # expected output : []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclusive_products(inventory1, inventory2):\n",
    "    # implement this\n",
    "    for i in range(len(inventory1)):\n",
    "        inventory1[i] = inventory1[i].upper() \n",
    "    \n",
    "    for i in range(len(inventory2)):\n",
    "        inventory2[i] = inventory2[i].upper() \n",
    "        \n",
    "    set1 = set(inventory1)\n",
    "    set2 = set(inventory2)\n",
    "    difference1 = set2 - set1\n",
    "    difference2 = set1 - set2\n",
    "    #difference = difference1 | difference2\n",
    "    return (sorted(list(difference2),reverse=False),sorted(list(difference1),reverse=False))\n",
    "    pass\n",
    "\n",
    "inventory1 = [\"Shirt\", \"Jeans\", \"Hat\"]\n",
    "inventory2 = [\"jeans\", \"Belt\", \"Boots\"]\n",
    "print(exclusive_products(inventory1, inventory2))\n",
    "# Expected output: (['HAT', 'SHIRT'], ['BELT', 'BOOTS'])\n",
    "\n",
    "inventory1 = [\"T-Shirt\", \"hoodie\", \"Backpack\"]\n",
    "inventory2 = [\"Backpack\", \"Hoodie\", \"t-shirt\"]\n",
    "print(exclusive_products(inventory1, inventory2))\n",
    "# Expected output: ([], [])\n",
    "\n",
    "inventory1 = []\n",
    "inventory2 = [\"Dress\", \"Skirt\", \"Coat\"]\n",
    "print(exclusive_products(inventory1, inventory2))\n",
    "# Expected output: ([], ['COAT', 'DRESS', 'SKIRT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango\n",
      "world\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_unique_string(words):\n",
    "    # implement this\n",
    "    seen = set()\n",
    "    duplicates = set()\n",
    "    for word in words:\n",
    "        if word in seen:\n",
    "            duplicates.add(word)\n",
    "        seen.add(word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in duplicates:\n",
    "            return word\n",
    "    return str('')\n",
    "    pass\n",
    "\n",
    "print(find_unique_string(['apple', 'banana', 'apple', 'mango', 'banana']))  # It should print: 'mango'\n",
    "print(find_unique_string(['hello', 'world', 'hello']))  # It should print: 'world'\n",
    "print(find_unique_string(['hello', 'world', 'hello', 'world']))  # It should print: ''\n",
    "print(find_unique_string([]))  # It should print: ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cinema', 'iceman']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def find_anagram_words(list_1, list_2):\n",
    "    # implement this\n",
    "    sorted_tuples_1 = set(tuple(sorted(word)) for word in list_1)\n",
    "    sorted_tuples_2 = set(tuple(sorted(word)) for word in list_2)\n",
    "    common_tuples = sorted_tuples_1 & sorted_tuples_2\n",
    "    \n",
    "    list_1_output = [word for word in list_1 if tuple(sorted(word)) in common_tuples]\n",
    "    #list_2_output = [word for word in list_2 if tuple(sorted(word)) in common_tuples]\n",
    "    \n",
    "    output = []\n",
    "    for word1 in list_1_output:\n",
    "    #for word2 in list_2_output:\n",
    "        if tuple(sorted(word1)) == tuple(sorted(word1)):\n",
    "                output.append((word1))\n",
    "    return output\n",
    "    \n",
    "    pass\n",
    "\n",
    "print(find_anagram_words(['cinema', 'iceman'], ['iceman', 'cinema'])) # should return ['cinema', 'iceman']\n",
    "print(find_anagram_words(['test', 'stet'], ['tent', 'nett'])) # should return []\n",
    "print(find_anagram_words(['hello', 'world'], ['dolly', 'sir'])) # should return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial book library:\n",
      "Book ID: 1, Title: The Catcher in the Rye\n",
      "Book ID: 2, Title: To Kill a Mockingbird\n",
      "Book ID: 3, Title: 1984\n",
      "\n",
      "Updated book library:\n",
      "Book ID: 1, Title: Moby-Dick\n",
      "Book ID: 2, Title: To Kill a Mockingbird\n",
      "Book ID: 3, Title: 1984\n",
      "\n",
      "Book library after deletion:\n",
      "Book ID: 1, Title: Moby-Dick\n",
      "Book ID: 3, Title: 1984\n"
     ]
    }
   ],
   "source": [
    "# Let's create a simple hash table in Python using dictionaries.\n",
    "\n",
    "# We'll store information about books in a library, where each book has a unique ID (key) and corresponding title (value).\n",
    "\n",
    "# Initialize an empty dictionary to serve as the hash table\n",
    "book_library = {}\n",
    "\n",
    "# Add some books to the dictionary\n",
    "book_library[1] = \"The Catcher in the Rye\"\n",
    "book_library[2] = \"To Kill a Mockingbird\"\n",
    "book_library[3] = \"1984\"\n",
    "\n",
    "# Print out the hash table/dictionary\n",
    "print(\"Initial book library:\")\n",
    "for key, value in book_library.items():\n",
    "    print(f\"Book ID: {key}, Title: {value}\")\n",
    "\n",
    "# Now, let's attempt to add a new book with an ID that's already used\n",
    "book_library[1] = \"Moby-Dick\"\n",
    "\n",
    "# Print out the updated dictionary\n",
    "print(\"\\nUpdated book library:\")\n",
    "for key, value in book_library.items():\n",
    "    print(f\"Book ID: {key}, Title: {value}\")\n",
    "\n",
    "# Let's remove the book with ID 2 from the dictionary\n",
    "del book_library[2]\n",
    "\n",
    "# Print out the dictionary after deletion operation\n",
    "print(\"\\nBook library after deletion:\")\n",
    "for key, value in book_library.items():\n",
    "    print(f\"Book ID: {key}, Title: {value}\")\n",
    "\n",
    "# The time complexity of adding, accessing, and deleting operations in a Python dictionary is O(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated upcoming events:\n",
      "Event ID: 1, Description: Coding Bootcamp - Monday, 8:00 AM\n",
      "Event ID: 2, Description: Data Structures - Tuesday 11:00\n",
      "Event ID: 3, Description: Data Science Meetup - Wednesday, 6:00 PM\n"
     ]
    }
   ],
   "source": [
    "# Create a Python dictionary that acts as a hash table\n",
    "event_system = {}\n",
    "\n",
    "# Add upcoming events\n",
    "event_system[1] = \"Coding Bootcamp - Monday, 8:00 AM\"\n",
    "event_system[2] = \"Python Webinar - Tuesday, 10:00 AM\"\n",
    "event_system[3] = \"Data Science Meetup - Wednesday, 6:00 PM\"\n",
    "\n",
    "# TODO: Update the Python Webinar description\n",
    "# Note: don't change previous definitions of `event_system` elements.\n",
    "event_system[2] = \"Data Structures - Tuesday 11:00\"\n",
    "\n",
    "# Print the updated events list\n",
    "print(\"\\nUpdated upcoming events:\")\n",
    "for event_id, event_desc in event_system.items():\n",
    "    print(f\"Event ID: {event_id}, Description: {event_desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Spacemail Log:\n",
      "Station: Station Alpha, Message: Supply request: cosmic fuel\n",
      "Station: Station Beta, Message: Engineering report: engines operational\n",
      "Station: Station Gamma, Message: Medical report: crew status healthy\n",
      "Updated Spacemail log\n",
      "Station: Station Alpha, Message: Supply request: cosmic fuel\n",
      "Station: Station Beta, Message: Engineering report: engines operational\n",
      "Station: Station Gamma, Message: Medical report: crew status healthy\n",
      "Station: Station Delta, Message: System report: Engines up and running\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary as a Hash Table\n",
    "spacemail = {}\n",
    "\n",
    "# Let's populate with incoming messages\n",
    "spacemail['Station Alpha'] = 'Supply request: cosmic fuel'\n",
    "spacemail['Station Beta'] = 'Engineering report: engines operational'\n",
    "spacemail['Station Gamma'] = 'Medical report: crew status healthy'\n",
    "\n",
    "# Let's print the initial spacemail log\n",
    "print(\"Initial Spacemail Log:\")\n",
    "for station, message in spacemail.items():\n",
    "    print(f\"Station: {station}, Message: {message}\")\n",
    "\n",
    "# TODO: Add a new message from Station Delta and verify the updated spacemail log\n",
    "spacemail['Station Delta'] = 'System report: Engines up and running'\n",
    "\n",
    "print(\"Updated Spacemail log\")\n",
    "for station, message in spacemail.items():\n",
    "    print(f\"Station: {station}, Message: {message}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hey', 1), ('there', 1), ('hot', 1), ('shot', 1), ('are', 1)]\n",
      "[('brown', 1), ('jumps', 1), ('over', 1), ('but', 1), ('quick', 2)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def rare_words_finder(text):\n",
    "    # implement this\n",
    "    text = text.lower()\n",
    "    word_count = defaultdict(int)\n",
    "    word_list = text.split()\n",
    "    for word in word_list:\n",
    "        word_count[word] += 1\n",
    "    less_appeared = sorted(word_count.items(),key = lambda x:x[1])[:5]\n",
    "    return less_appeared\n",
    "\n",
    "    pass\n",
    "\n",
    "print(rare_words_finder(\"Hey there hot shot Are you ready for a challenge This might be trickier than it looks\")) # Expected Output: [('hey', 1), ('there', 1), ('hot', 1), ('shot', 1), ('are', 1)]\n",
    "\n",
    "print(rare_words_finder(\"The quick brown fox jumps over the lazy dog The fox is quick but the dog is lazy\")) # Expected Output: [('brown', 1), ('jumps', 1), ('over', 1), ('but', 1), ('quick', 2)]\n",
    "\n",
    "print(rare_words_finder(\"\")) # Expected Output: []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length': True, 'digit': False, 'lowercase': True, 'uppercase': False, 'special_char': False}\n",
      "{'length': True, 'digit': True, 'lowercase': True, 'uppercase': True, 'special_char': True}\n",
      "{'length': True, 'digit': False, 'lowercase': True, 'uppercase': True, 'special_char': True}\n",
      "{'length': False, 'digit': False, 'lowercase': True, 'uppercase': False, 'special_char': False}\n"
     ]
    }
   ],
   "source": [
    "def multi_password_strength_counter(passwords):\n",
    "    special_characters = \"!@#$%^&*()-+\"\n",
    "    list = []\n",
    "    for password in passwords:\n",
    "        strength = {\n",
    "        'length' : False,\n",
    "        'digit' : False,\n",
    "        'lowercase' : False,\n",
    "        'uppercase' : False,\n",
    "        'special_char':False\n",
    "        }\n",
    "        if len(password) >= 8:\n",
    "            strength['length'] = True\n",
    "        for char in password:\n",
    "            if char.isdigit():\n",
    "                strength['digit'] = True\n",
    "            elif char.islower():\n",
    "                strength['lowercase'] = True\n",
    "            elif char.isupper():\n",
    "                strength['uppercase'] = True\n",
    "            elif char in (special_characters):\n",
    "                strength['special_char'] = True\n",
    "        list.append(strength)\n",
    "    return list    \n",
    "    \n",
    "    # implement this\n",
    "    pass\n",
    "\n",
    "passwords = [\"password\", \"Pa$$w0rd\", \"SuperSecurePwd!\", \"weakpw\"]\n",
    "results = multi_password_strength_counter(passwords)\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'John', 'role': 'developer', 'salary': 57500.0}, {'name': 'Mary', 'role': 'developer', 'salary': 80500.0}, {'name': 'Jim', 'role': 'manager', 'salary': 85000}]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def salary_increment(employees):\n",
    "    # implement this\n",
    "    for employee in employees:\n",
    "        bonus = 0\n",
    "        if employee['role'] == 'developer':\n",
    "            bonus = employee['salary'] * 0.15\n",
    "        employee['salary'] = employee['salary'] + bonus\n",
    "    return employees\n",
    "    pass\n",
    "\n",
    "# Test cases\n",
    "\n",
    "employees = [{\n",
    "    'name': 'John',\n",
    "    'role': 'developer',\n",
    "    'salary': 50000\n",
    "}, {\n",
    "    'name': 'Mary',\n",
    "    'role': 'developer',\n",
    "    'salary': 70000\n",
    "}, {\n",
    "    'name': 'Jim',\n",
    "    'role': 'manager',\n",
    "    'salary': 85000\n",
    "}]\n",
    "\n",
    "print(salary_increment(employees))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
