{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Set Test Result: False\n",
      "Searching in the Hash Set Took: 0.00019288063049316406\n",
      "List Test Result: False\n",
      "Searching in the List Took: 0.1782698631286621\n"
     ]
    }
   ],
   "source": [
    "# Define a function to demonstrate the operation and time complexity of a hash set\n",
    "def hash_set_operations():\n",
    "  \n",
    "    # Importing the necessary libraries\n",
    "    import time\n",
    "    \n",
    "    # Create a hash set and a list\n",
    "    hash_set = set()\n",
    "    list_data = []\n",
    "    \n",
    "    # Setting the range for the data elements\n",
    "    data_range = 10**7\n",
    "    \n",
    "    # Adding elements to the hash set and the list\n",
    "    for i in range(data_range):\n",
    "        hash_set.add(i)\n",
    "        list_data.append(i)\n",
    "        \n",
    "    # Define a test element (which is out of the data range and thus is not present in both the list and set)\n",
    "    test_element = data_range + 1\n",
    "    \n",
    "    # Start the clock and check for the presence of the test elements in the set\n",
    "    start_time = time.time()\n",
    "    print(\"Hash Set Test Result:\", test_element in hash_set)\n",
    "    print(\"Searching in the Hash Set Took:\", time.time() - start_time)\n",
    "  \n",
    "    # Start the clock and check for the presence of the test elements in the list\n",
    "    start_time = time.time()\n",
    "    print(\"List Test Result:\", test_element in list_data)\n",
    "    print(\"Searching in the List Took:\", time.time() - start_time)\n",
    "\n",
    "# Call the function\n",
    "hash_set_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Set Test Result 1: False\n",
      "Hash Set Test Result 2: True\n",
      "Searching in the Hash Set Took: 0.0009441375732421875\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary module\n",
    "import time\n",
    "\n",
    "# Define a function to demonstrate the operation and time complexity of hash sets\n",
    "def hash_set_operations():\n",
    "  \n",
    "    # Create a new hash set \n",
    "    names_set = set()\n",
    "\n",
    "    # Setting the range for the data elements\n",
    "    data_range = 10**7\n",
    "\n",
    "    # Constructing a unique names list\n",
    "    unique_names = ['Name' + str(i) for i in range(data_range)]\n",
    "\n",
    "    # Adding elements to the set\n",
    "    for i in range(data_range):\n",
    "        names_set.add(unique_names[i])\n",
    "\n",
    "    # Define a test element (which is out of the data range and thus is not present in the set)\n",
    "    test_name = 'Name' + str(data_range + 1)\n",
    "\n",
    "    # Define a test element that should exist\n",
    "    test_name2 = 'Name' + str(data_range - 1)\n",
    "\n",
    "    # Start the clock and check for the presence of the test elements in the set\n",
    "    start_time = time.time()\n",
    "    print(\"Hash Set Test Result 1:\", test_name in names_set)\n",
    "    print(\"Hash Set Test Result 2:\", test_name2 in names_set)\n",
    "    print(\"Searching in the Hash Set Took:\", time.time() - start_time)\n",
    "\n",
    "# Call the function\n",
    "hash_set_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def compare_operations():\n",
    "    # Create a list and a set\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    data_set = set()\n",
    "\n",
    "\n",
    "\n",
    "    # Adding elements to list and set\n",
    "\n",
    "    for i in range(10**6):\n",
    "\n",
    "        data_list.append(i)\n",
    "\n",
    "        data_set.add(i)\n",
    "\n",
    "\n",
    "\n",
    "    # Set and List are ready; now let's define a non-existing item to search for\n",
    "\n",
    "    test_item = 10**6 + 1 \n",
    "\n",
    "    # Time the 100 consecutive operations of checking whether `test_item` is in `data_set`\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        if test_item in data_set:\n",
    "            pass  # Do nothing if found (expected not to find)\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken for 100 set lookups:\", end_time - start_time)\n",
    "\n",
    "    # Time the 100 consecutive operations of checking whether `test_item` is in `data_list`\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        if test_item in data_list:\n",
    "            pass  # Do nothing if found (expected not to find)\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken for 100 list lookups:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to demonstrate the operation and time complexity of a hash set\n",
    "\n",
    "def compare_operations():\n",
    "\n",
    "  \n",
    "\n",
    "    # Create a list and a set\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    data_set = set()\n",
    "\n",
    "\n",
    "\n",
    "    # Adding elements to list and set\n",
    "\n",
    "    for i in range(10**6):\n",
    "\n",
    "        data_list.append(i)\n",
    "\n",
    "        data_set.add(i)\n",
    "\n",
    "\n",
    "\n",
    "    # Set and List are ready; now let's define a non-existing item to search for\n",
    "\n",
    "    test_item = 10**6 + 1  # This item is not in our set or list\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: Time the 100 consecutive operations of checking whether `test_item` is in `data_set` and print the result and time taken\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: Time the 100 consecutive operations of checking whether `test_item` is in `data_list` and print the result and time taken\n",
    "\n",
    "\n",
    "\n",
    "# Execute the function\n",
    "\n",
    "compare_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the instersection of elements in two lists using sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 8, 7, 6, 5]\n",
      "[-1, -2, -3, -4, -5]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def intersecting_elements(set1, set2):\n",
    "    # implement this\n",
    "    set1 = set(set1)\n",
    "    set2 = set(set2)\n",
    "    intersection = set1 & set2\n",
    "    return sorted(list(intersection),reverse=True)\n",
    "    pass\n",
    "\n",
    "print(intersecting_elements({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {5, 6, 7, 8, 9, 10, 11, 12, 13, 14}))\n",
    "# Expected output: [10, 9, 8, 7, 6, 5]\n",
    "\n",
    "print(intersecting_elements({-1, -2, -3, -4, -5}, {-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5}))\n",
    "# Expected output: [-1, -2, -3, -4, -5]\n",
    "\n",
    "print(intersecting_elements({1, 3, 5, 7, 9}, {2, 4, 6, 8, 10}))\n",
    "# Expected output: []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using set to find repeating elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7]\n",
      "[2, 3, -1]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def repeating_elements(nums):\n",
    "    # implement this\n",
    "    seen , repeated = set(),set()\n",
    "    for num in nums:\n",
    "        if num in seen:\n",
    "            repeated.add(num)\n",
    "        else:\n",
    "            seen.add(num)\n",
    "    return list(repeated)\n",
    "    pass\n",
    "\n",
    "print(repeating_elements([9, 8, 7, 8, 7, 6, 5]))  # expected output : [8, 7]\n",
    "print(repeating_elements([-1, 2, 3, -1, 2, 3]))   # expected output : [-1, 2, 3]\n",
    "print(repeating_elements([1, 2, 3, 4, 5]))        # expected output : []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclusive_products(inventory1, inventory2):\n",
    "    # implement this\n",
    "    for i in range(len(inventory1)):\n",
    "        inventory1[i] = inventory1[i].upper() \n",
    "    \n",
    "    for i in range(len(inventory2)):\n",
    "        inventory2[i] = inventory2[i].upper() \n",
    "        \n",
    "    set1 = set(inventory1)\n",
    "    set2 = set(inventory2)\n",
    "    difference1 = set2 - set1\n",
    "    difference2 = set1 - set2\n",
    "    #difference = difference1 | difference2\n",
    "    return (sorted(list(difference2),reverse=False),sorted(list(difference1),reverse=False))\n",
    "    pass\n",
    "\n",
    "inventory1 = [\"Shirt\", \"Jeans\", \"Hat\"]\n",
    "inventory2 = [\"jeans\", \"Belt\", \"Boots\"]\n",
    "print(exclusive_products(inventory1, inventory2))\n",
    "# Expected output: (['HAT', 'SHIRT'], ['BELT', 'BOOTS'])\n",
    "\n",
    "inventory1 = [\"T-Shirt\", \"hoodie\", \"Backpack\"]\n",
    "inventory2 = [\"Backpack\", \"Hoodie\", \"t-shirt\"]\n",
    "print(exclusive_products(inventory1, inventory2))\n",
    "# Expected output: ([], [])\n",
    "\n",
    "inventory1 = []\n",
    "inventory2 = [\"Dress\", \"Skirt\", \"Coat\"]\n",
    "print(exclusive_products(inventory1, inventory2))\n",
    "# Expected output: ([], ['COAT', 'DRESS', 'SKIRT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango\n",
      "world\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_unique_string(words):\n",
    "    # implement this\n",
    "    seen = set()\n",
    "    duplicates = set()\n",
    "    for word in words:\n",
    "        if word in seen:\n",
    "            duplicates.add(word)\n",
    "        seen.add(word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in duplicates:\n",
    "            return word\n",
    "    return str('')\n",
    "    pass\n",
    "\n",
    "print(find_unique_string(['apple', 'banana', 'apple', 'mango', 'banana']))  # It should print: 'mango'\n",
    "print(find_unique_string(['hello', 'world', 'hello']))  # It should print: 'world'\n",
    "print(find_unique_string(['hello', 'world', 'hello', 'world']))  # It should print: ''\n",
    "print(find_unique_string([]))  # It should print: ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
